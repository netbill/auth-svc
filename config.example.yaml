service:
  name: "auth-svc"

log:
  level: "debug"
  format: "text"

database:
  sql:
    url: "postgresql://postgres:postgres@localhost:7001/postgres?sslmode=disable"

rest:
  port: ":8001"
  timeouts:
    read: 15s #seconds
    read_header: 15s #seconds
    write: 15s #seconds
    idle: 60s #seconds


auth:
  tokens:
    account_access:
      secret_key: "UnG06MAU2i1Mvqf8" #example
      ttl: 12h #12 hours
    account_refresh:
      secret_key: "6DSjhhT9KIezubpR" #example
      hash_key: "Zlyh20N8uojZHFdO" #Key for decrypting Refresh Token in the database
      ttl: 720h #30 days

  oauth:
    google:
      client_id: "client_id"
      client_secret: "megasupersecret"
      redirect_url: "http://localhost:8001/v1/sso/google/login/callback"

kafka:
  brokers:
    - "localhost:9092"

  identity: "auth-svc" # used for consumer group and client id

  produce:
    topics:
      accounts_v1: #topic name for accounts events
        required_acks: "all"     # "all" | "one" | "none"
        compression: "snappy"    # "snappy" | "gzip" | "lz4" | "zstd" | "none"
        balancer: "hash"         # "least_bytes" | "round_robin" | "hash"
        batch_size: 100          # sender batching (0 = default)
        batch_timeout: 10ms      # sender batching timeout (0 = default)
        write_timeout: 5s        # timeout for a write call (0 = default)
        read_timeout: 5s         # broker read timeout (0 = default)
        dial_timeout: 5s         # dial timeout (0 = default)
        idle_timeout: 30s        # close idle connections (0 = default)

  consume:
    topics:
      organization_members_v1:
        instances: 4           # number of readers for this topic which will be started in each process
        min_bytes: 1           # minimum bytes to fetch in each request
        max_bytes: 10e6        # maximum bytes to fetch in each request
        max_wait: 1s           # maximum time to wait for messages in each request
        queue_capacity: 10     # capacity of the internal queue for messages fetched from Kafka

      organizations_v1:
        instances: 4           # number of readers for this topic which will be started in each process
        min_bytes: 1           # minimum bytes to fetch in each request
        max_bytes: 10e6        # maximum bytes to fetch in each request
        max_wait: 1s           # maximum time to wait for messages in each request
        queue_capacity: 10     # capacity of the internal queue for messages fetched from Kafka

  inbox:
    routines: 10          #number of goroutines which can process messages in each process
    slots: 40             #number of slots for processing messages in each process (should be >= routines)
    sleep: 100ms          #sleep time between processing messages
    batch_size: 100       #number of messages to process in a batch in each process
    min_next_attempt: 1m  #minimum time to wait before retrying a failed message
    max_next_attempt: 10m #maximum time to wait before retrying a failed message
    max_attempts: 0       #maximum number of attempts to process a message before giving up (0 = infinite retries)

  outbox:
    routines: 10          #number of goroutines which can process messages in each process
    slots: 40             #number of slots for processing messages in each process (should be >= routines)
    sleep: 100ms          #sleep time between processing messages
    batch_size: 100       #number of messages to process in a batch in each process
    min_next_attempt: 1m  #minimum time to wait before retrying a failed message
    max_next_attempt: 10m #maximum time to wait before retrying a failed message
    max_attempts: 0       #maximum number of attempts to process a message before giving up (0 = infinite retries)


